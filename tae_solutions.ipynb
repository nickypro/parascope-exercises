{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76eefbac-976c-422d-9c2c-9bf526b25978",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " # Section 1: Text Autoencoders - Exploring SONAR\n",
    " This notebook explores Meta's SONAR text autoencoder, which can encode text\n",
    " into fixed-size vectors and decode them back to (approximately) the original text.\n",
    " Learning objectives:\n",
    " 1. Load and use SONAR for text encoding/decoding\n",
    " 2. Understand the properties of text embeddings\n",
    " 3. Test robustness to noise\n",
    " 4. Explore how text length affects embeddings\n",
    " 5. Experiment with token swapping and sentence combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4f67e-0109-47ea-a442-d843bed1cc50",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Setup and Installation\n",
    "\n",
    " First, we need to install SONAR and its dependencies. Just run, nothing worth reading here unless you get errors.\n",
    " Note: You may need to adjust the CUDA version in fairseq2 installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772feac0-5fca-440c-8a55-635576a6ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "!pip install -q fairseq2==0.4.5 sonar-space==0.4.0 torchvision==0.21.0 torch==2.6.0 torchaudio==2.6.0 plotly nbformat\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sonar.inference_pipelines.text import TextToEmbeddingModelPipeline\n",
    "from sonar.inference_pipelines.text import EmbeddingToTextModelPipeline\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "from jaxtyping import Float\n",
    "\n",
    "# Check if CUDA is available\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE = torch.device(DEVICE)\n",
    "torch.set_grad_enabled(False)  # We're only doing inference\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4ee27-025f-4c56-8af7-4d94b947f906",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Loading SONAR Models\n",
    "\n",
    " SONAR (Sentence-Level Multimodal and Language-Agnostic Representations) is Meta's text autoencoder\n",
    " that can encode entire sentences/paragraphs into fixed-size vectors and decode them back to approximately\n",
    " the original text.\n",
    "\n",
    " **What are Text Autoencoders?**\n",
    "\n",
    " Text Autoencoders are models that compress entire input sequences (sentences/paragraphs) into a single\n",
    " fixed-size vector representation (the \"bottleneck\"), then reconstruct the original text from that vector.\n",
    " Unlike typical text embedding models that only encode, these models have both an encoder AND decoder.\n",
    "\n",
    " ![Text Autoencoder Architecture](https://39669.cdn.cke-cs.com/rQvD3VnunXZu34m86e5f/images/db8d350884974ce6dcb1281011c5053e11b65711c12a4556.png)\n",
    "\n",
    " **How Text Autoencoders Work:**\n",
    " 1. **Encoder**: Takes input text → processes through Transformer → outputs single fixed-size vector (1024-dim)\n",
    " 2. **Bottleneck**: The compressed representation that captures semantic meaning in a dense vector\n",
    " 3. **Decoder**: Takes the vector → generates text that approximates the original input\n",
    "\n",
    " **Key Properties:**\n",
    " - **Lossy compression**: Some information is lost, but semantic meaning is preserved\n",
    " - **Fixed-size representation**: Any length text becomes same-size vector (useful for comparison/clustering)\n",
    " - **Cross-lingual**: Can encode in one language and decode in another\n",
    " - **Reconstruction capability**: Unlike embedding-only models, you can decode back to text\n",
    " - **Semantic preservation**: The bottleneck captures core meaning even with compression\n",
    "\n",
    " **SONAR Specifically:**\n",
    " - Trained on ~100B tokens with denoising and translation objectives\n",
    " - Uses 24-layer Transformer encoder and decoder, with mean-pooling to create the bottleneck vector\n",
    " - Supports 200+ languages and can handle up to 512 tokens of context\n",
    " - Currently one of the best-performing text autoencoders available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d2d89-fd17-4e48-ae30-8419cafd63ec",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " We start by loading the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f8761-b726-42ea-9567-6b46329eb89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading SONAR models...\")\n",
    "text2vec = TextToEmbeddingModelPipeline(\n",
    "    encoder=\"text_sonar_basic_encoder\",\n",
    "    tokenizer=\"text_sonar_basic_encoder\",\n",
    "    device=DEVICE\n",
    ")\n",
    "vec2text = EmbeddingToTextModelPipeline(\n",
    "    decoder=\"text_sonar_basic_decoder\",\n",
    "    tokenizer=\"text_sonar_basic_encoder\",\n",
    "    device=DEVICE\n",
    ")\n",
    "print(\"Models loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1478648-794c-41c5-b68d-2aeb5f4e4df2",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Basic Usage - Encoding and Decoding\n",
    "\n",
    " Test basic encoding and decoding functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c128205-6a81-4351-b111-93232b259d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Simple example sentences\n",
    "sentences = [\n",
    "    'My name is SONAR.',\n",
    "    'I can embed sentences into vectorial space.'\n",
    "]\n",
    "\n",
    "# Encode sentences to vectors\n",
    "embeddings = text2vec.predict(sentences, source_lang=\"eng_Latn\")\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")  # Should be [2, 1024]\n",
    "print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
    "print(f\"L2 norm of embeddings: {torch.norm(embeddings, dim=1).tolist()}\")\n",
    "\n",
    "# Decode vectors back to text\n",
    "reconstructed = vec2text.predict(embeddings, target_lang=\"eng_Latn\", max_seq_len=512)\n",
    "print(\"\\nReconstruction quality:\")\n",
    "for orig, rec in zip(sentences, reconstructed):\n",
    "    print(f\"Original:      {orig}\")\n",
    "    print(f\"Reconstructed: {rec}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55337e21-8703-4b20-b3e3-42fe95b15597",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## Exercise 1: Testing with Longer, More Realistic Text\n",
    " Let's test how well SONAR handles paragraph-length text.\n",
    "\n",
    " Write a function to reconstruct text from SONAR embeddings, and try testing with some longer text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528c62f7-2bb6-4f7c-a381-fbde9ce03a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_text(texts: list[str]) -> list[str]:\n",
    "    \"\"\"Reconstruct text from SONAR embedding, by first encoding and then decoding the text.\n",
    "\n",
    "    Args:\n",
    "        texts: List of strings to embed and then reconstruct.\n",
    "\n",
    "    Returns:\n",
    "        List of reconstructed strings.\n",
    "    \"\"\"\n",
    "    # [your implementation here]\n",
    "    embedding = text2vec.predict(texts, source_lang=\"eng_Latn\")\n",
    "    return vec2text.predict(embedding, target_lang=\"eng_Latn\", max_seq_len=512)\n",
    "\n",
    "# Longer example paragraphs\n",
    "paragraph1 = \"\"\"SONAR is a model from August 2023, trained as a semantic text auto-encoder,\n",
    "converting text into semantic embed vectors, which can later be decoded back into text.\n",
    "Additionally, the model is trained such that the semantic embed vectors are to some degree\n",
    "\"universal\" for different languages, and one can embed in French and decode in English.\"\"\"\n",
    "\n",
    "paragraph2 = \"\"\"I tried it, and SONAR seems to work surprisingly well. For example, the above\n",
    "paragraph and this paragraph, if each are encoded into two 1024 dimensional vectors\n",
    "(one for each paragraph), the model returns the following decoded outputs.\"\"\"\n",
    "\n",
    "paragraph3 = \"\"\"\\\n",
    "Your text here.\n",
    "\"\"\"\n",
    "\n",
    "# Test with paragraphs\n",
    "long_texts = [paragraph1, paragraph2, paragraph3]\n",
    "long_reconstructed = reconstruct_text(long_texts)\n",
    "\n",
    "print(\"Paragraph reconstruction:\")\n",
    "for i, (orig, rec) in enumerate(zip(long_texts, long_reconstructed)):\n",
    "    print(f\"\\n--- Paragraph {i+1} ---\")\n",
    "    print(f\"Original ({len(orig)} chars):\")\n",
    "    print(orig[:100] + \"...\" if len(orig) > 100 else orig)\n",
    "    print(f\"\\nReconstructed ({len(rec)} chars):\")\n",
    "    print(rec[:100] + \"...\" if len(rec) > 100 else rec)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
